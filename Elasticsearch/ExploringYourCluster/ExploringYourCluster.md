# Exploring Your Cluster #

## The REST API ##

Now that we have our node (and cluster) up and running, the next step is to understand how to communicate with it. Fortunately, Elasticsearch provides a very comprehensive and powerful REST API that you can use to interact with your cluster. Among the few things that can be done with the API are as follows:

+ Check your cluster, node, and index health, status, and statistics
+ Administer your cluster, node, and index data and metadata
+ Perform CRUD (Create, Read, Update, and Delete) and search operations against your indexes
+ Execute advanced search operations such as paging, sorting, filtering, scripting, aggregations, and many others

## Cluster Health ##

Letâ€™s start with a basic health check, which we can use to see how our cluster is doing. Weâ€™ll be using curl to do this but you can use any tool that allows you to make HTTP/REST calls. Letâ€™s assume that we are still on the same node where we started Elasticsearch on and open another command shell window.

![1](1.jpg)

åœ¨å…³æ‰éªŒè¯ä¹‹åï¼ˆå‚è€ƒInstall.mdï¼‰

![2](2.jpg)

![3](3.jpg)

Whenever we ask for the cluster health, we either get green, yellow, or red. Green means everything is good (cluster is fully functional), yellow means all data is available but some replicas are not yet allocated (cluster is fully functional), and red means some data is not available for whatever reason. Note that even if a cluster is red, it still is partially functional (i.e. it will continue to serve search requests from the available shards) but you will likely need to fix it ASAP since you have missing data.

> ç»¿è‰²æ˜¯å…¨éƒ¨èŠ‚ç‚¹å¥åº·ï¼Œé»„è‰²æ˜¯å¤‡ä»½èŠ‚ç‚¹æ²¡æœ‰è¶³å¤Ÿçš„æ§ä»¶å»åˆ†é…ï¼ˆä½†æ˜¯åŠŸèƒ½æ­£å¸¸ï¼‰
>
> æ˜¯æ—¶å€™ç”³è¯·ä¸€å°å†…å­˜æ¯”è¾ƒå¤§çš„äº‘ä¸»æœº
>
> å³ä½¿æ˜¯çº¢è‰²ä¹Ÿåªæ˜¯ä¸¢å¤±éƒ¨åˆ†æ•°æ®

Also from the above response, we can see a total of 1 node and that we have 0 shards since we have no data in it yet. Note that since we are using the default cluster name (elasticsearch) and since Elasticsearch uses unicast network discovery by default to find other nodes on the same machine, it is possible that you could accidentally start up more than one node on your computer and have them all join a single cluster. In this scenario, you may see more than 1 node in the above response.

> æœ‰å¯èƒ½çœ‹åˆ°ä¸æ­¢ä¸€ä¸ªèŠ‚ç‚¹

![4](4.jpg)

å¯ä»¥çœ‹åˆ°å†…å­˜å¾ˆä¸ä¹è§‚ï¼Œ2Gå†…å­˜çš„æœºå­æ’‘ä¸ä½ElasticSearch

## List All Indices ##

![5](5.jpg)

æˆ‘ä¹Ÿä¸çŸ¥é“é‡Œé¢ä¸ºä»€ä¹ˆä¼šæœ‰æ•°æ®ï¼Œæˆ‘ä¹Ÿå¾ˆæ— å¥ˆï¼ˆé‚£åˆæ€ä¹ˆåŠï¼Ÿï¼‰

## Create an Index ##

![6](6.jpg)

è¯·æ±‚æ–¹æ³•æ˜¯PUTæ–¹æ³•ï¼Œè·¯å¾„æ˜¯`/æ–°åˆ›å»ºçš„Indice?pretty`

The first command creates the index named "customer" using the PUT verb. We simply append pretty to the end of the call to tell it to pretty-print the JSON response (if any).

> prettyå‘Šè¯‰æœåŠ¡å™¨ï¼Œè¯·ç»™æˆ‘ä¸€ä¸ªå¥½çœ‹ä¸€ç‚¹çš„JSON

![7](7.jpg)

You might also notice that the customer index has a yellow health tagged to it. Recall from our previous discussion that yellow means that some replicas are not (yet) allocated. The reason this happens for this index is because Elasticsearch by default created one replica for this index. Since we only have one node running at the moment, that one replica cannot yet be allocated (for high availability) until a later point in time when another node joins the cluster. Once that replica gets allocated onto a second node, the health status for this index will turn to green.

> ä¾‹å­ä¹Ÿç¢°åˆ°äº†è¿™ä¸ªé—®é¢˜ï¼Œå› ä¸ºå®ƒçš„é›†ç¾¤ä¹Ÿåªæœ‰ä¸€ä¸ªèŠ‚ç‚¹ï¼Œæ‰€ä»¥æ²¡åŠæ³•å¤‡ä»½ï¼Œå¯¼è‡´æ•°æ®çš„å¥åº·çŠ¶æ€æ˜¯yellow
>
> å®ƒä¹‹å‰é›†ç¾¤çš„çŠ¶æ€æ˜¯greenåªæ˜¯å› ä¸ºé›†ç¾¤å†…æ²¡æœ‰æ•°æ®ç½¢äº†

## Index and Query a Document ##

Letâ€™s now put something into our customer index. Remember previously that in order to index a document, we must tell Elasticsearch which type in the index it should go to.

> è¿˜è®°å¾—ä¸¤çº§åˆ†ç±»å—ï¼Ÿè¾“å…¥æ•°æ®çš„æ—¶å€™è¦å‘Šè¯‰æœåŠ¡å™¨æ•°æ®å±äºçš„Indiceï¼Type

Letâ€™s now put something into our customer index. Remember previously that in order to index a document, we must tell Elasticsearch which type in the index it should go to.

Letâ€™s index a simple customer document into the customer index, "external" type, with an ID of 1 as follows:

![8](8.jpg)

![9](9.jpg)

è¯·æŠŠBodyè®¾ç½®æˆJSONæ ¼å¼

From the above, we can see that a new customer document was successfully created inside the customer index and the external type. The document also has an internal id of 1 which we specified at index time.

> åœ¨ä¸Šé¢çš„è¯·æ±‚ä¸­ï¼Œæˆ‘ä»¬å¸¦ä¸Šäº†_idï¼Œè¿™åœ¨å®é™…åº”ç”¨ä¸­æ˜¯ä¸ç°å®çš„
>
> _idâ€¦...å‘µå‘µå‘µï¼Œè¿™ä¸€å®šæ˜¯MongoDBçš„å¼€å‘äººå‘˜å–çš„åå­—
>
> æ¥ä¸‹æ¥ï¼ŒæŒ‰ç…§MongoDBçš„å¥—è·¯ï¼Œåº”è¯¥ä¼šè¯´å¦‚æœä¸å¸¦_idï¼Œæˆ‘ä»¬ä¼šç”¨ç®—æ³•éšæœºç”Ÿæˆä¸€ä¸ªï¼Œç®—æ³•è€ƒè™‘äº†æ—¶é—´ï¼è¿›ç¨‹idç­‰

It is important to note that Elasticsearch does not require you to explicitly create an index first before you can index documents into it. In the previous example, Elasticsearch will automatically create the customer index if it didnâ€™t already exist beforehand.

> è¿™ä¸ªå¥—è·¯æ·±å¾—æˆ‘å¿ƒï¼Œæˆ‘ä»¬æ¥å®éªŒä¸€ä¸‹

![10](10.jpg)

![11](11.jpg)

æ³¨æ„è¦æŠŠPUTæ–¹æ³•æ”¹æˆPOSTæ–¹æ³•ï¼Œç„¶åä¸éœ€è¦å¸¦ä¸Šid

æ³¨æ„è¿”å›çš„JSONä¸­å‘Šè¯‰äº†æˆ‘ä»¬ç”Ÿæˆçš„idæ˜¯å¤šå°‘

Letâ€™s now retrieve that document that we just indexed:

```http
http://118.89.166.180:9200/customer/external/AV0wemsyBmuWI_ALnrc3?pretty
```

![12](12.jpg)

Nothing out of the ordinary here other than a field, found, stating that we found a document with the requested ID 1 and another field, _source, which returns the full JSON document that we indexed from the previous step.

> ä¼šåŒ…å«ä¸€äº›å…ƒä¿¡æ¯

## Delete an Index ##

![13](13.jpg)

å¦‚æœä½ è®¿é—®ä¸€ä¸‹`GET /_cat/indices?v`ï¼Œä¼šçœ‹åˆ°customer Indiceå·²ç»è¢«åˆ é™¤äº†

Before we move on, letâ€™s take a closer look again at some of the API commands that we have learned so far:

> å¤ä¹ å¤ä¹ 

```http
PUT /customer
PUT /customer/external/1
{
  "name": "John Doe"
}
GET /customer/external/1
DELETE /customer
```

If we study the above commands carefully, we can actually see a pattern of how we access data in Elasticsearch. That pattern can be summarized as follows:

```http
<REST Verb> /<Index>/<Type>/<ID>
```

> æ€»ç»“å‡ºæ¥çš„æ¨¡å¼å¾ˆå…³é”®
>
> æŒ‰ç…§è¿™ä¸ªæ¨¡å¼ï¼Œdocumentçš„åˆ é™¤ï¼æ›´æ–°ä¹Ÿä¸éš¾è‡ªå·±å†™å‡ºæ¥

This REST access pattern is so pervasive throughout all the API commands that if you can simply remember it, you will have a good head start at mastering Elasticsearch.

## Modifying Your Data ##

Elasticsearch provides data manipulation and search capabilities in near real time. By default, you can expect a one second delay (refresh interval) from the time you index/update/delete your data until the time that it appears in your search results. This is an important distinction from other platforms like SQL wherein data is immediately available after a transaction is completed.

> å¯¹äºNRTæˆ‘åªæœ‰ä¸€å¥å‘µå‘µå¯ä»¥è¯´ï¼ŒåŸæ¥æ¯”å…¶å®ƒäº§å“å·®ä¹Ÿå¯ä»¥æ‰¾ä¸€ä¸ªçœ‹ä¸Šå»è¿™ä¹ˆé«˜ç«¯çš„è¯è¯­
>
> æå¾—æˆ‘ä¸€å¼€å§‹çœ‹åˆ°å®ƒè¿˜ä»¥ä¸ºæ˜¯ElasticSearchçš„ä¼˜åŠ¿

### Indexing/Replacing Documents ###

Weâ€™ve previously seen how we can index a single document. Letâ€™s recall that command again:

![14](14.jpg)

Again, the above will index the specified document into the customer index, external type, with the ID of 1. If we then executed the above command again with a different (or same) document, Elasticsearch will replace (i.e. reindex) a new document on top of the existing one with the ID of 1:

> æˆ‘ä»¬çš„`id`æ˜¯20ï¼Œå› ä¸ºæˆ‘å–œæ¬¢å’Œä»–çš„å¥—è·¯ä¸ä¸€æ ·ğŸ˜Š

![15](15.jpg)

åŒæ ·çš„è¯·æ±‚ï¼Œå†è¯·æ±‚ä¸€æ¬¡å°±æ˜¯update

![16](16.jpg)

å¯ä»¥çœ‹åˆ°æ•°æ®å·²ç»æ›´æ–°äº†

When indexing, the ID part is optional. If not specified, Elasticsearch will generate a random ID and then use it to index the document. The actual ID Elasticsearch generates (or whatever we specified explicitly in the previous examples) is returned as part of the index API call.

> æ— `id`æ•°æ®æ’å…¥åœ¨å‰é¢æ¼”ç¤ºè¿‡äº†

## Updating Documents ##

ä¸‹é¢æˆ‘ä»¬æœ‰è¯·æ‰¹æ“ä½œå‡ºåœº

In addition to being able to index and replace documents, we can also update documents. Note though that Elasticsearch does not actually do in-place updates under the hood. Whenever we do an update, Elasticsearch deletes the old document and then indexes a new document with the update applied to it in one shot.

> update = delete + insert
>
> å‡½æ•°å¼ç¼–ç¨‹è¯­è¨€é£æ ¼ï¼Ÿ

This example shows how to update our previous document (ID of 1) by changing the name field to "Jane Doe" and at the same time add an age field to it:

```http
POST /customer/external/1/_update?pretty
{
  "doc": { "name": "Jane Doe", "age": 20 }
}
```

è¿™ä¸ªå˜å¾—æœ‰ä¸€ç‚¹ç‚¹å¥‡æ€ªï¼ŒåŠ¨è¯å‡ºç°äºè·¯å¾„ä¹‹ä¸­ï¼Œè€Œä¸”bodyä¹Ÿæœ‰ä¸€ç‚¹ç‚¹å¥‡æ€ª

Updates can also be performed by using simple scripts. This example uses a script to increment the age by 5:

```http
POST /customer/external/1/_update?pretty
{
  "script" : "ctx._source.age += 5"
}
```

In the above example, ctx._source refers to the current source document that is about to be updated.

> å¾ˆç¨³ï¼Œè¿˜æ”¯æŒè„šæœ¬ä¿®æ”¹

Note that as of this writing, updates can only be performed on a single document at a time. In the future, Elasticsearch might provide the ability to update multiple documents given a query condition (like an SQL UPDATE-WHERE statement).

> æˆ‘é”™äº†ï¼Œè¿™é‡Œè¿˜æ²¡æœ‰è®²åˆ°æ‰¹æ“ä½œï¼Œåªæ˜¯ä¸€ç§æ›´é«˜çº§çš„update
>
> æˆ‘æ¯”è¾ƒå…³å¿ƒçš„é—®é¢˜ï¼šæ˜¯å¦æ”¯æŒå‡çº§ç‰¹å®šçš„åŸŸï¼Ÿ

## Deleting Documents ##

```shell
DELETE /customer/external/2?pretty
```

See the Delete By Query API to delete all documents matching a specific query. It is worth noting that it is much more efficient to delete a whole index instead of deleting all documents with the Delete By Query AP

> æœ‰æ›´åŠ é«˜çº§çš„æ–¹æ³•
>
> ååˆ†æ€€ç–‘ElasticSearchèƒŒåçš„ç”·äººæ˜¯MongoDBï¼ˆ(ï½¡Ã¬ _ Ã­ï½¡)ï¼‰

## Batch Processing ##

provides the ability to perform any of the above operations in batches using the _bulk API. This functionality is important in that it provides a very efficient mechanism to do multiple operations as fast as possible with as few network roundtrips as possible.

> `_bulk`ï¼Œå…„å¼ŸğŸ‘¬ï¼Œä½ ä»¬åå­—éƒ½ä¸€æ¯›ä¸€æ ·çš„ä¹ˆï¼Ÿ

As a quick example, the following call indexes two documents (ID 1 - John Doe and ID 2 - Jane Doe) in one bulk operation:

```http
POST /customer/external/_bulk?pretty
{"index":{"_id":"1"}}
{"name": "John Doe" }
{"index":{"_id":"2"}}
{"name": "Jane Doe" }
```

> è¿™ä¸ªAPIè®¾è®¡çš„æ²¡æœ‰MongoDBçš„å¥½

This example updates the first document (ID of 1) and then deletes the second document (ID of 2) in one bulk operation:

```http
POST /customer/external/_bulk?pretty
{"update":{"_id":"1"}}
{"doc": { "name": "John Doe becomes Jane Doe" } }
{"delete":{"_id":"2"}}
```

Note above that for the delete action, there is no corresponding source document after it since deletes only require the ID of the document to be deleted.

> è¿™ç§ä¸€å¸¦ä¸€çš„ä¸œè¥¿çœ‹èµ·æ¥å¾ˆå¥‡æ€ª
>
> è¿˜ä¸å¦‚æŠŠéœ€è¦çš„å‚æ•°æ”¾åˆ°åŒä¸€ä¸ªmapé‡Œ

The Bulk API does not fail due to failures in one of the actions. If a single action fails for whatever reason, it will continue to process the remainder of the actions after it. When the bulk API returns, it will provide a status for each action (in the same order it was sent in) so that you can check if a specific action failed or not.

> çœ‹æ¥æ˜¯å¹¶è¡Œæ‰§è¡Œ

## Exploring Your Data ##

### Sample Dataset ###

```shell
curl -H "Content-Type: application/json" -XPOST '118.89.166.180:9200/bank/account/_bulk?pretty&refresh' --data-binary "@accounts.json"
```

![17](17.jpg)

Which means that we just successfully bulk indexed 1000 documents into the bank index (under the account type).

> 1000ä¸ªæ•°æ®å·²ç»æˆåŠŸå¯¼å…¥

## The Search API ##

Now letâ€™s start with some simple searches. There are two basic ways to run searches: one is by sending search parameters through the REST request URI and the other by sending them through the REST request body. The request body method allows you to be more expressive and also to define your searches in a more readable JSON format. Weâ€™ll try one example of the request URI method but for the remainder of this tutorial, we will exclusively be using the request body method.

> ç”¨bodyä¼šæ›´åŠ å…·æœ‰å¯è¯»æ€§

The REST API for search is accessible from the _search endpoint. This example returns all documents in the bank index:

```http
GET /bank/_search?q=*&sort=account_number:asc&pretty
```

![18](18.jpg)

è¿™ä½¿ç”¨urlä¼ é€’å‚æ•°ï¼Œä¸å…·å¤‡å¾ˆå¥½çš„å¯è¯»æ€§ï¼Œæˆ‘ä»¬ä¸ä¼šå¾ˆè¯¦ç»†åœ°å»è§£æè¿™ä¸ªurl

Letâ€™s first dissect the search call. We are searching (_search endpoint) in the bank index, and the q=* parameter instructs Elasticsearch to match all documents in the index. The sort=account_number:asc parameter indicates to sort the results using the account_number field of each document in an ascending order. The pretty parameter, again, just tells Elasticsearch to return pretty-printed JSON results.

As for the response, we see the following parts:

+ took â€“ time in milliseconds for Elasticsearch to execute the search

  > è€—æ—¶

+ timed_out â€“ tells us if the search timed out or not

  > æŸ¥è¯¢æ˜¯å¦è¶…æ—¶

+ _shards â€“ tells us how many shards were searched, as well as a count of the successful/failed searched shards

  > æœ‰å¤šå°‘ä¸ªshardå‚ä¸æœ¬æ¬¡æŸ¥è¯¢

+ hits â€“ search results

+ hits.total â€“ total number of documents matching our search criteria

+ hits.hits â€“ actual array of search results (defaults to first 10 documents)

+ hits.sort - sort key for results (missing if sorting by score)

Here is the same exact search above using the alternative request body method:

```http
GET /bank/_search
{
  "query": { "match_all": {} },
  "sort": [
    { "account_number": "asc" }
  ]
}
```

> æœ‰ä¸€ç§MongoDBçš„å‘³é“
>
> å®é™…å®éªŒå‘ç°ï¼Œç”¨POSTæ–¹æ³•ä¹Ÿå¯ä»¥è¯·æ±‚åˆ°ç›¸åŒçš„ç»“æœ

The difference here is that instead of passing q=* in the URI, we POST a JSON-style query request body to the _search API. Weâ€™ll discuss this JSON query in the next section.

It is important to understand that once you get your search results back, Elasticsearch is completely done with the request and does not maintain any kind of server-side resources or open cursors into your results. This is in stark contrast to many other platforms such as SQL wherein you may initially get a partial subset of your query results up-front and then you have to continuously go back to the server if you want to fetch (or page through) the rest of the results using some kind of stateful server-side cursor.

> æœåŠ¡ç«¯æ²¡æœ‰çŠ¶æ€æ˜¯ä¸€ä»¶å¥½äº‹ï¼Œä¸è¿‡é—®é¢˜åœ¨äºæ¯”å¦‚æˆ‘æƒ³åŠ è½½å‰100ä¸ªæ€ä¹ˆåŠï¼ŸåŠ è½½å‰100ä¸ªçš„åˆ†é¡µè¦æˆ‘è‡ªå·±åšå—ï¼Ÿ

## Introducing the Query Language ##

Elasticsearch provides a JSON-style domain-specific language that you can use to execute queries. This is referred to as the Query DSL. The query language is quite comprehensive and can be intimidating at first glance but the best way to actually learn it is to start with a few basic examples.

> ä¸å¹¸çš„æ¶ˆæ¯ï¼ŒæŸ¥è¯¢è¯­è¨€å¾ˆå¤æ‚
>
> å¸Œæœ›å®ƒå’ŒMongoDBçš„æŸ¥è¯¢è¯­è¨€ç±»ä¼¼

Going back to our last example, we executed this query:

```http
GET /bank/_search
{
  "query": { "match_all": {} }
}
```

Dissecting the above, the query part tells us what our query definition is and the match_all part is simply the type of query that we want to run. The match_all query is simply a search for all documents in the specified index.

In addition to the query parameter, we also can pass other parameters to influence the search results. In the example in the section above we passed in sort, here we pass in size:

```http
GET /bank/_search
{
  "query": { "match_all": {} },
  "size": 1
}
```

Note that if size is not specified, it defaults to 10.

This example does a match_all and returns documents 11 through 20:

```http
GET /bank/_search
{
  "query": { "match_all": {} },
  "from": 10,
  "size": 10
}
```

> å¯ä»¥è¿™ä¸ªå¾ˆæ–¹ä¾¿ï¼Œä¸è¿‡å¦‚æœæ²¡æœ‰ç¼“å­˜ï¼ˆæœåŠ¡å™¨æ— çŠ¶æ€ï¼‰ï¼Œè¿™æ ·åšä¼šä¸ä¼šå½±å“æ•ˆç‡ï¼Ÿ

The from parameter (0-based) specifies which document index to start from and the size parameter specifies how many documents to return starting at the from parameter. This feature is useful when implementing paging of search results. Note that if from is not specified, it defaults to 0.

This example does a match_all and sorts the results by account balance in descending order and returns the top 10 (default size) documents.

```http
GET /bank/_search
{
  "query": { "match_all": {} },
  "sort": { "balance": { "order": "desc" } }
}
```

## Executing Searches ##

